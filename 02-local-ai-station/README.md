## ğŸš€ Enterprise Local AI Infrastructure (On-Premise)
System lokalnej infrastruktury AI klasy Enterprise, zaprojektowany z myÅ›lÄ… o prywatnoÅ›ci danych i maksymalnej wydajnoÅ›ci obliczeniowej.

### âš™ï¸ Architektura i Stack Techniczny
Infrastruktura oparta na dedykowanej stacji roboczej **NVIDIA RTX 5090 (32GB VRAM)**, zoptymalizowana pod kÄ…tem modeli o parametrach 32B-70B.

* **Orkiestracja:** n8n (Self-hosted via Docker).
* **Modele LLM:** Ollama (DeepSeek-R1 32B, Qwen 2.5 32B).
* **Bazy danych:** Supabase (PostgreSQL + pgvector) oraz Qdrant (Vector Store).
* **ObserwowalnoÅ›Ä‡:** Langfuse (Monitoring Å›ladÃ³w AI, latencji i zuÅ¼ycia tokenÃ³w).
* **System:** Ubuntu 24.04 LTS z optymalizacjÄ… PCIe 5.0 oraz Re-Size BAR.

### ğŸ› ï¸ GÅ‚Ã³wne FunkcjonalnoÅ›ci
1.  **Lokalny RAG (Retrieval-Augmented Generation):** Hybrydowe wyszukiwanie danych Å‚Ä…czÄ…ce zapytania SQL z przeszukiwaniem wektorowym.
2.  **PeÅ‚na PrywatnoÅ›Ä‡:** Å»adne dane firmowe (prompty, dokumenty, dane klientÃ³w) nie opuszczajÄ… sieci lokalnej.
3.  **Monitoring WydajnoÅ›ci:** PeÅ‚ny tracing procesÃ³w myÅ›lowych agentÃ³w w Langfuse, pozwalajÄ…cy na debugowanie promptÃ³w w czasie rzeczywistym.

### ğŸ“Š Benchmark (RTX 5090)
* **Model:** Mistral Small 3.2 (Lokalnie)
* **Åšrednia Latencja:** 2.7s (peÅ‚ny cykl agenta z narzÄ™dziami)
* **VRAM Usage:** ~19GB / 32GB`
